{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-07 11:35:21,428 - mmseg - INFO - Loaded 2000 images\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: pretrain/seg_diff_20t_160k.pth\n",
      "[                                                  ] 0/2000, elapsed: 0s, ETA:"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import os.path as osp\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "from mmcv.image import tensor2imgs\n",
    "import mmcv\n",
    "import torch\n",
    "from mmcv.cnn.utils import revert_sync_batchnorm\n",
    "from mmcv.parallel import MMDataParallel, MMDistributedDataParallel\n",
    "from mmcv.runner import (get_dist_info, init_dist, load_checkpoint,\n",
    "                         wrap_fp16_model)\n",
    "from mmcv.utils import DictAction\n",
    "from mmseg.datasets import build_dataloader, build_dataset\n",
    "from mmseg.models import build_segmentor\n",
    "from mmseg.utils import setup_multi_processes\n",
    "from mmseg.ops import resize\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import numpy as np\n",
    "config=\"configs/segdiffusion/upernet_beit-base_512x512_160k_ade20k_20t_kl_loss.py\"\n",
    "checkpoint=\"pretrain/seg_diff_20t_160k.pth\"\n",
    "gpu_ids=[0]\n",
    "cfg = mmcv.Config.fromfile(config)\n",
    "dataset = build_dataset(cfg.data.test)\n",
    "loader_cfg = dict(\n",
    "    # cfg.gpus will be ignored if distributed\n",
    "    num_gpus=1,\n",
    "    dist=False)\n",
    "# The overall dataloader settings\n",
    "loader_cfg.update({\n",
    "    k: v\n",
    "    for k, v in cfg.data.items() if k not in [\n",
    "        'train', 'val', 'test', 'train_dataloader', 'val_dataloader',\n",
    "        'test_dataloader'\n",
    "    ]\n",
    "})\n",
    "test_loader_cfg = {\n",
    "    **loader_cfg,\n",
    "    'samples_per_gpu': len(gpu_ids),\n",
    "    'shuffle': False,  # Not shuffle by default\n",
    "    **cfg.data.get('test_dataloader', {})\n",
    "}\n",
    "# build the dataloader\n",
    "data_loader = build_dataloader(dataset, **test_loader_cfg)\n",
    "model = build_segmentor(cfg.model, test_cfg=cfg.get('test_cfg'))\n",
    "checkpoint = load_checkpoint(model, checkpoint, map_location='cpu')\n",
    "if 'CLASSES' in checkpoint.get('meta', {}):\n",
    "    model.CLASSES = checkpoint['meta']['CLASSES']\n",
    "else:\n",
    "    print('\"CLASSES\" not found in meta, use dataset.CLASSES instead')\n",
    "    model.CLASSES = dataset.CLASSES\n",
    "if 'PALETTE' in checkpoint.get('meta', {}):\n",
    "    model.PALETTE = checkpoint['meta']['PALETTE']\n",
    "else:\n",
    "    print('\"PALETTE\" not found in meta, use dataset.PALETTE instead')\n",
    "    model.PALETTE = dataset.PALETTE\n",
    "torch.cuda.empty_cache()\n",
    "model = revert_sync_batchnorm(model)\n",
    "#model = MMDataParallel(model, device_ids=gpu_ids)\n",
    "model=model.cuda()\n",
    "\n",
    "def make_grid(imgs,rows=0,margin=5):\n",
    "    H,W,C=imgs[0].shape\n",
    "    li=len(imgs)\n",
    "    if not rows:\n",
    "        rows=int(np.floor(np.sqrt(li)))\n",
    "    cols=int(np.ceil(li/rows))\n",
    "    pad=np.zeros(((H+margin)*rows-margin,(W+margin)*cols-margin,3),dtype=np.uint8)\n",
    "    for  i in range(li):\n",
    "        rs=i//cols\n",
    "        ls=i%cols\n",
    "        pad[rs*(H+margin):rs*(H+margin)+H,ls*(W+margin):ls*(W+margin)+W]=imgs[i]\n",
    "    return pad\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def slide_inference(model, img):\n",
    "    h_stride, w_stride = model.test_cfg.stride\n",
    "    h_crop, w_crop = model.test_cfg.crop_size\n",
    "    batch_size, _, h_img, w_img = img.size()\n",
    "    num_classes = model.num_classes\n",
    "    h_grids = max(h_img - h_crop + h_stride - 1, 0) // h_stride + 1\n",
    "    w_grids = max(w_img - w_crop + w_stride - 1, 0) // w_stride + 1\n",
    "    crop_images=[]\n",
    "    for h_idx in range(h_grids):\n",
    "        for w_idx in range(w_grids):\n",
    "            y1 = h_idx * h_stride\n",
    "            x1 = w_idx * w_stride\n",
    "            y2 = min(y1 + h_crop, h_img)\n",
    "            x2 = min(x1 + w_crop, w_img)\n",
    "            y1 = max(y2 - h_crop, 0)\n",
    "            x1 = max(x2 - w_crop, 0)\n",
    "            crop_img = img[:, :, y1:y2, x1:x2]\n",
    "            crop_images.append(crop_img)\n",
    "    def merge_fn(patches):\n",
    "        preds = torch.zeros((batch_size, num_classes, h_img, w_img),device=\"cpu\")\n",
    "        count_mat = torch.zeros((batch_size, 1, h_img, w_img),device=\"cpu\")\n",
    "        i=0\n",
    "        for h_idx in range(h_grids):\n",
    "            for w_idx in range(w_grids):\n",
    "                y1 = h_idx * h_stride\n",
    "                x1 = w_idx * w_stride\n",
    "                y2 = min(y1 + h_crop, h_img)\n",
    "                x2 = min(x1 + w_crop, w_img)\n",
    "                y1 = max(y2 - h_crop, 0)\n",
    "                x1 = max(x2 - w_crop, 0)\n",
    "                crop_seg_logit = patches[i].cpu()\n",
    "                i+=1\n",
    "                preds += F.pad(crop_seg_logit,\n",
    "                                (int(x1), int(preds.shape[3] - x2), int(y1),\n",
    "                                int(preds.shape[2] - y2)))\n",
    "                count_mat[:, :, y1:y2, x1:x2] += 1\n",
    "        assert (count_mat == 0).sum() == 0\n",
    "        preds = preds / count_mat\n",
    "        return preds\n",
    "    return crop_images, merge_fn\n",
    "\n",
    "\n",
    "def single_gpu_test(model,data_loader,out_dir=None,opacity=0.5):\n",
    "    model.eval()\n",
    "    results = []\n",
    "    dataset = data_loader.dataset\n",
    "    prog_bar = mmcv.ProgressBar(len(dataset))\n",
    "    loader_indices = data_loader.batch_sampler\n",
    "    counter=0\n",
    "    os.makedirs(\"work_dirs/seg_diff/visualize/\",exist_ok=True)\n",
    "    for batch_indices, data in zip(loader_indices, data_loader):\n",
    "        with torch.no_grad():\n",
    "            img_tensor = data['img'][0]\n",
    "            img_metas = data['img_metas'][0].data[0]\n",
    "            imgs = tensor2imgs(img_tensor, **img_metas[0]['img_norm_cfg'])\n",
    "            assert len(imgs) == len(img_metas)\n",
    "            crop_images, merge_fn = slide_inference(model, img_tensor.cuda())\n",
    "            ts=[[] for i in range(len(crop_images))]\n",
    "            zs=[[] for i in range(len(crop_images))]\n",
    "            xs=[[] for i in range(len(crop_images))]\n",
    "            outs=[]\n",
    "            for i in range(len(crop_images)):\n",
    "                def call_back(log_z,log_x_recon,t,**args):\n",
    "                    ts[i].append(t[0].item())\n",
    "                    zs[i].append(resize(input=torch.exp(log_z[:,:-1]),size=crop_images[0].shape[2:],mode='bilinear',align_corners=model.align_corners).cpu())\n",
    "                    xs[i].append(resize(input=torch.exp(log_x_recon[:,:-1]),size=crop_images[0].shape[2:],mode='bilinear',align_corners=model.align_corners).cpu())\n",
    "                out = model.sample(crop_images[i],return_logits = True,call_back=call_back)\n",
    "                out = out['logits'][:,:-1]\n",
    "                out = resize(input=out,size=crop_images[0].shape[2:],mode='bilinear',align_corners=model.align_corners)\n",
    "                outs.append(out)\n",
    "            out=merge_fn(outs)\n",
    "            zs=[merge_fn(i) for i in  zip(*zs)]\n",
    "            xs=[merge_fn(i) for i in  zip(*xs)]\n",
    "            ts=ts[0]\n",
    "            img=imgs[0]\n",
    "            img_meta=img_metas[0]\n",
    "            h, w, _ = img_meta['img_shape']\n",
    "            img_show = img[:h, :w, :]\n",
    "            ori_h, ori_w = img_meta['ori_shape'][:-1]\n",
    "            img_show = mmcv.imresize(img_show, (ori_w, ori_h))\n",
    "            showed_img_out=model.show_result(img_show,torch.argmax(resize(out, (ori_h, ori_w),mode='bilinear',align_corners=model.align_corners),1),opacity=opacity)\n",
    "            showed_zt_out=make_grid([model.show_result(img_show,torch.argmax(resize(i, (ori_h, ori_w),mode='bilinear',align_corners=model.align_corners),1),opacity=opacity) for i in zs])\n",
    "            showed_xt_out=make_grid([model.show_result(img_show,torch.argmax(resize(i, (ori_h, ori_w),mode='bilinear',align_corners=model.align_corners),1),opacity=opacity) for i in xs])\n",
    "            cv2.imwrite(\"work_dirs/seg_diff/visualize/%s_seg.png\"%counter,showed_img_out)\n",
    "            cv2.imwrite(\"work_dirs/seg_diff/visualize/%s_zt.png\"%counter,showed_zt_out)\n",
    "            cv2.imwrite(\"work_dirs/seg_diff/visualize/%s_xt.png\"%counter,showed_xt_out)\n",
    "            counter+=1\n",
    "        batch_size = len(outs)\n",
    "        for _ in range(batch_size):\n",
    "            prog_bar.update()\n",
    "\n",
    "\n",
    "zs=single_gpu_test(model,data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t= 0  mask tokens:  0  mask tokens:  349696\n",
      "t= 1  mask tokens:  18426  mask tokens:  331270\n",
      "t= 2  mask tokens:  29325  mask tokens:  320371\n",
      "t= 3  mask tokens:  41055  mask tokens:  308641\n",
      "t= 4  mask tokens:  53411  mask tokens:  296285\n",
      "t= 5  mask tokens:  66723  mask tokens:  282973\n",
      "t= 6  mask tokens:  80375  mask tokens:  269321\n",
      "t= 7  mask tokens:  94900  mask tokens:  254796\n",
      "t= 8  mask tokens:  110119  mask tokens:  239577\n",
      "t= 9  mask tokens:  126167  mask tokens:  223529\n",
      "t= 10  mask tokens:  142813  mask tokens:  206883\n",
      "t= 11  mask tokens:  160051  mask tokens:  189645\n",
      "t= 12  mask tokens:  178087  mask tokens:  171609\n",
      "t= 13  mask tokens:  196827  mask tokens:  152869\n",
      "t= 14  mask tokens:  216690  mask tokens:  133006\n",
      "t= 15  mask tokens:  237119  mask tokens:  112577\n",
      "t= 16  mask tokens:  257800  mask tokens:  91896\n",
      "t= 17  mask tokens:  279769  mask tokens:  69927\n",
      "t= 18  mask tokens:  302422  mask tokens:  47274\n",
      "t= 19  mask tokens:  325770  mask tokens:  23926\n"
     ]
    }
   ],
   "source": [
    "for i,j in enumerate(zs[::-1]):\n",
    "    j=torch.argmax(j,dim=1)\n",
    "    mask=torch.sum(j==149).item()\n",
    "    unmask=torch.sum(j!=149).item()\n",
    "    print(\"t=\",i,\" mask tokens: \",mask,\" unmask tokens: \",unmask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
