{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-13 04:03:56,898 - mmseg - INFO - Loaded 2000 images\n",
      "/public/zhaohanqing/anaconda3/envs/py3x/lib/python3.10/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755897462/work/aten/src/ATen/native/TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "/ssd/zhaohanqing/msws/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:232: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: pretrain/seg_diff_20t_160k.pth\n",
      "[                               ] 1/2000, 0.1 task/s, elapsed: 11s, ETA: 22823s"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 1.82 GiB (GPU 0; 23.70 GiB total capacity; 13.66 GiB already allocated; 1.31 GiB free; 20.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/ssd/zhaohanqing/msws/mmsegmentation/test.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 224>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcluster.weiming.win/ssd/zhaohanqing/msws/mmsegmentation/test.ipynb#ch0000000vscode-remote?line=219'>220</a>\u001b[0m         \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(batch_size):\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcluster.weiming.win/ssd/zhaohanqing/msws/mmsegmentation/test.ipynb#ch0000000vscode-remote?line=220'>221</a>\u001b[0m             prog_bar\u001b[39m.\u001b[39mupdate()\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bcluster.weiming.win/ssd/zhaohanqing/msws/mmsegmentation/test.ipynb#ch0000000vscode-remote?line=223'>224</a>\u001b[0m single_gpu_test(model,data_loader)\n",
      "\u001b[1;32m/ssd/zhaohanqing/msws/mmsegmentation/test.ipynb Cell 1'\u001b[0m in \u001b[0;36msingle_gpu_test\u001b[0;34m(model, data_loader, out_dir, opacity)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcluster.weiming.win/ssd/zhaohanqing/msws/mmsegmentation/test.ipynb#ch0000000vscode-remote?line=194'>195</a>\u001b[0m img_show \u001b[39m=\u001b[39m img[:h, :w, :]\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcluster.weiming.win/ssd/zhaohanqing/msws/mmsegmentation/test.ipynb#ch0000000vscode-remote?line=195'>196</a>\u001b[0m ori_h, ori_w \u001b[39m=\u001b[39m img_meta[\u001b[39m'\u001b[39m\u001b[39mori_shape\u001b[39m\u001b[39m'\u001b[39m][:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bcluster.weiming.win/ssd/zhaohanqing/msws/mmsegmentation/test.ipynb#ch0000000vscode-remote?line=196'>197</a>\u001b[0m uc_map\u001b[39m=\u001b[39m[resize(extract_uc(i), (ori_h, ori_w),mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbilinear\u001b[39m\u001b[39m'\u001b[39m,align_corners\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39malign_corners) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m xs]\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcluster.weiming.win/ssd/zhaohanqing/msws/mmsegmentation/test.ipynb#ch0000000vscode-remote?line=197'>198</a>\u001b[0m img_show \u001b[39m=\u001b[39m mmcv\u001b[39m.\u001b[39mimresize(img_show, (ori_w, ori_h))\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcluster.weiming.win/ssd/zhaohanqing/msws/mmsegmentation/test.ipynb#ch0000000vscode-remote?line=198'>199</a>\u001b[0m showed_img_out\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39mshow_result(img_show,torch\u001b[39m.\u001b[39margmax(resize(out, (ori_h, ori_w),mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbilinear\u001b[39m\u001b[39m'\u001b[39m,align_corners\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39malign_corners),\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mcpu(),opacity\u001b[39m=\u001b[39mopacity)\n",
      "\u001b[1;32m/ssd/zhaohanqing/msws/mmsegmentation/test.ipynb Cell 1'\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcluster.weiming.win/ssd/zhaohanqing/msws/mmsegmentation/test.ipynb#ch0000000vscode-remote?line=194'>195</a>\u001b[0m img_show \u001b[39m=\u001b[39m img[:h, :w, :]\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcluster.weiming.win/ssd/zhaohanqing/msws/mmsegmentation/test.ipynb#ch0000000vscode-remote?line=195'>196</a>\u001b[0m ori_h, ori_w \u001b[39m=\u001b[39m img_meta[\u001b[39m'\u001b[39m\u001b[39mori_shape\u001b[39m\u001b[39m'\u001b[39m][:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bcluster.weiming.win/ssd/zhaohanqing/msws/mmsegmentation/test.ipynb#ch0000000vscode-remote?line=196'>197</a>\u001b[0m uc_map\u001b[39m=\u001b[39m[resize(extract_uc(i), (ori_h, ori_w),mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbilinear\u001b[39m\u001b[39m'\u001b[39m,align_corners\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39malign_corners) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m xs]\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcluster.weiming.win/ssd/zhaohanqing/msws/mmsegmentation/test.ipynb#ch0000000vscode-remote?line=197'>198</a>\u001b[0m img_show \u001b[39m=\u001b[39m mmcv\u001b[39m.\u001b[39mimresize(img_show, (ori_w, ori_h))\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcluster.weiming.win/ssd/zhaohanqing/msws/mmsegmentation/test.ipynb#ch0000000vscode-remote?line=198'>199</a>\u001b[0m showed_img_out\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39mshow_result(img_show,torch\u001b[39m.\u001b[39margmax(resize(out, (ori_h, ori_w),mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbilinear\u001b[39m\u001b[39m'\u001b[39m,align_corners\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39malign_corners),\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mcpu(),opacity\u001b[39m=\u001b[39mopacity)\n",
      "\u001b[1;32m/ssd/zhaohanqing/msws/mmsegmentation/test.ipynb Cell 1'\u001b[0m in \u001b[0;36mextract_uc\u001b[0;34m(logits_aux)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcluster.weiming.win/ssd/zhaohanqing/msws/mmsegmentation/test.ipynb#ch0000000vscode-remote?line=44'>45</a>\u001b[0m logits_aux\u001b[39m=\u001b[39mF\u001b[39m.\u001b[39munfold(logits_aux,\u001b[39m3\u001b[39m,stride\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcluster.weiming.win/ssd/zhaohanqing/msws/mmsegmentation/test.ipynb#ch0000000vscode-remote?line=45'>46</a>\u001b[0m logits_aux\u001b[39m=\u001b[39meinops\u001b[39m.\u001b[39mrearrange(logits_aux,\u001b[39m\"\u001b[39m\u001b[39mB (c t1 t2) (H W) -> B c (t1 t2) H W\u001b[39m\u001b[39m\"\u001b[39m,t1\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m,t2\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m,H\u001b[39m=\u001b[39mH,W\u001b[39m=\u001b[39mW)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bcluster.weiming.win/ssd/zhaohanqing/msws/mmsegmentation/test.ipynb#ch0000000vscode-remote?line=46'>47</a>\u001b[0m uc_map\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39;49meinsum(\u001b[39m\"\u001b[39;49m\u001b[39mabcde,abcde->ade\u001b[39;49m\u001b[39m\"\u001b[39;49m,x,logits_aux)\u001b[39m/\u001b[39m\u001b[39m9\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcluster.weiming.win/ssd/zhaohanqing/msws/mmsegmentation/test.ipynb#ch0000000vscode-remote?line=47'>48</a>\u001b[0m \u001b[39mreturn\u001b[39;00m uc_map\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/py3x/lib/python3.10/site-packages/torch/functional.py:330\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    <a href='file:///public/zhaohanqing/anaconda3/envs/py3x/lib/python3.10/site-packages/torch/functional.py?line=325'>326</a>\u001b[0m     \u001b[39m# recurse incase operands contains value that has torch function\u001b[39;00m\n\u001b[1;32m    <a href='file:///public/zhaohanqing/anaconda3/envs/py3x/lib/python3.10/site-packages/torch/functional.py?line=326'>327</a>\u001b[0m     \u001b[39m# in the original implementation this line is omitted\u001b[39;00m\n\u001b[1;32m    <a href='file:///public/zhaohanqing/anaconda3/envs/py3x/lib/python3.10/site-packages/torch/functional.py?line=327'>328</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m einsum(equation, \u001b[39m*\u001b[39m_operands)\n\u001b[0;32m--> <a href='file:///public/zhaohanqing/anaconda3/envs/py3x/lib/python3.10/site-packages/torch/functional.py?line=329'>330</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _VF\u001b[39m.\u001b[39;49meinsum(equation, operands)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1.82 GiB (GPU 0; 23.70 GiB total capacity; 13.66 GiB already allocated; 1.31 GiB free; 20.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import os.path as osp\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "from mmcv.image import tensor2imgs\n",
    "import mmcv\n",
    "import torch\n",
    "from mmcv.cnn.utils import revert_sync_batchnorm\n",
    "from mmcv.parallel import MMDataParallel, MMDistributedDataParallel\n",
    "from mmcv.runner import (get_dist_info, init_dist, load_checkpoint,\n",
    "                         wrap_fp16_model)\n",
    "from mmcv.utils import DictAction\n",
    "from mmseg.datasets import build_dataloader, build_dataset\n",
    "from mmseg.models import build_segmentor\n",
    "from mmseg.utils import setup_multi_processes\n",
    "from mmseg.ops import resize\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import numpy as np\n",
    "import einops\n",
    "config=\"configs/segdiffusion/upernet_beit-base_512x512_160k_ade20k_20t_kl_loss.py\"\n",
    "checkpoint=\"pretrain/seg_diff_20t_160k.pth\"\n",
    "sample_bias=10\n",
    "gpu_ids=[0]\n",
    "cfg = mmcv.Config.fromfile(config)\n",
    "dataset = build_dataset(cfg.data.test)\n",
    "inference_with_uc=True\n",
    "def mod_log_z_by_uc(log_z,uc,t):\n",
    "    rate=1.0/20.0/19.0*t\n",
    "    gate=torch.quantile(uc, 1-rate)\n",
    "    to_mask=uc>gate\n",
    "    mask=torch.zeros_like(log_z)\n",
    "    mask[:,-1]=1\n",
    "    mask = torch.log(mask.clamp(min=1e-30))\n",
    "    p=to_mask*mask+(~to_mask)*log_z\n",
    "    log_z.data.copy_(p)\n",
    "\n",
    "def extract_uc(logits_aux):\n",
    "    #print(logits_aux.sum(dim=1))\n",
    "    x=einops.repeat(-torch.log(logits_aux),\"B C H W -> B C 9 H W\")\n",
    "    B,C,_,H,W=x.shape\n",
    "    logits_aux=F.pad(logits_aux,(1,1,1,1),\"reflect\")\n",
    "    logits_aux=F.unfold(logits_aux,3,stride=1)\n",
    "    logits_aux=einops.rearrange(logits_aux,\"B (c t1 t2) (H W) -> B c (t1 t2) H W\",t1=3,t2=3,H=H,W=W)\n",
    "    uc_map=torch.einsum(\"abcde,abcde->ade\",x,logits_aux)/9\n",
    "    return uc_map.unsqueeze(1)\n",
    "\n",
    "loader_cfg = dict(\n",
    "    # cfg.gpus will be ignored if distributed\n",
    "    num_gpus=1,\n",
    "    dist=False)\n",
    "# The overall dataloader settings\n",
    "loader_cfg.update({\n",
    "    k: v\n",
    "    for k, v in cfg.data.items() if k not in [\n",
    "        'train', 'val', 'test', 'train_dataloader', 'val_dataloader',\n",
    "        'test_dataloader'\n",
    "    ]\n",
    "})\n",
    "test_loader_cfg = {\n",
    "    **loader_cfg,\n",
    "    'samples_per_gpu': len(gpu_ids),\n",
    "    'shuffle': False,  # Not shuffle by default\n",
    "    **cfg.data.get('test_dataloader', {})\n",
    "}\n",
    "# build the dataloader\n",
    "data_loader = build_dataloader(dataset, **test_loader_cfg)\n",
    "model = build_segmentor(cfg.model, test_cfg=cfg.get('test_cfg'))\n",
    "checkpoint = load_checkpoint(model, checkpoint, map_location='cpu')\n",
    "if 'CLASSES' in checkpoint.get('meta', {}):\n",
    "    model.CLASSES = checkpoint['meta']['CLASSES']\n",
    "else:\n",
    "    print('\"CLASSES\" not found in meta, use dataset.CLASSES instead')\n",
    "    model.CLASSES = dataset.CLASSES\n",
    "if 'PALETTE' in checkpoint.get('meta', {}):\n",
    "    model.PALETTE = checkpoint['meta']['PALETTE']\n",
    "else:\n",
    "    print('\"PALETTE\" not found in meta, use dataset.PALETTE instead')\n",
    "    model.PALETTE = dataset.PALETTE\n",
    "torch.cuda.empty_cache()\n",
    "model = revert_sync_batchnorm(model)\n",
    "#model = MMDataParallel(model, device_ids=gpu_ids)\n",
    "model=model.cuda()\n",
    "\n",
    "def make_grid(imgs,rows=0,margin=5):\n",
    "    H,W,C=imgs[0].shape\n",
    "    li=len(imgs)\n",
    "    if not rows:\n",
    "        rows=int(np.floor(np.sqrt(li)))\n",
    "    cols=int(np.ceil(li/rows))\n",
    "    pad=np.zeros(((H+margin)*rows-margin,(W+margin)*cols-margin,3),dtype=np.uint8)\n",
    "    for  i in range(li):\n",
    "        rs=i//cols\n",
    "        ls=i%cols\n",
    "        pad[rs*(H+margin):rs*(H+margin)+H,ls*(W+margin):ls*(W+margin)+W]=imgs[i]\n",
    "    return pad\n",
    "\n",
    "def vis_uc(x,color):\n",
    "    color=np.array(color).reshape(1,1,3)\n",
    "    x=x/np.max(x)\n",
    "    return np.expand_dims(x,-1)*color\n",
    "    \n",
    "\n",
    "def slide_inference(model, img):\n",
    "    h_stride, w_stride = model.test_cfg.stride\n",
    "    h_crop, w_crop = model.test_cfg.crop_size\n",
    "    batch_size, _, h_img, w_img = img.size()\n",
    "    num_classes = model.num_classes\n",
    "    h_grids = max(h_img - h_crop + h_stride - 1, 0) // h_stride + 1\n",
    "    w_grids = max(w_img - w_crop + w_stride - 1, 0) // w_stride + 1\n",
    "    crop_images=[]\n",
    "    for h_idx in range(h_grids):\n",
    "        for w_idx in range(w_grids):\n",
    "            y1 = h_idx * h_stride\n",
    "            x1 = w_idx * w_stride\n",
    "            y2 = min(y1 + h_crop, h_img)\n",
    "            x2 = min(x1 + w_crop, w_img)\n",
    "            y1 = max(y2 - h_crop, 0)\n",
    "            x1 = max(x2 - w_crop, 0)\n",
    "            crop_img = img[:, :, y1:y2, x1:x2]\n",
    "            crop_images.append(crop_img)\n",
    "    def merge_fn(patches):\n",
    "        preds = torch.zeros((batch_size, num_classes+1, h_img, w_img),device=patches[0].device)\n",
    "        count_mat = torch.zeros((batch_size, 1, h_img, w_img),device=patches[0].device)\n",
    "        i=0\n",
    "        for h_idx in range(h_grids):\n",
    "            for w_idx in range(w_grids):\n",
    "                y1 = h_idx * h_stride\n",
    "                x1 = w_idx * w_stride\n",
    "                y2 = min(y1 + h_crop, h_img)\n",
    "                x2 = min(x1 + w_crop, w_img)\n",
    "                y1 = max(y2 - h_crop, 0)\n",
    "                x1 = max(x2 - w_crop, 0)\n",
    "                crop_seg_logit = patches[i]\n",
    "                B,C,H,W=crop_seg_logit.shape\n",
    "                i+=1\n",
    "                preds[:,:C,y1:y2, x1:x2]+=crop_seg_logit\n",
    "                # preds += F.pad(crop_seg_logit,\n",
    "                #                 (int(x1), int(preds.shape[3] - x2), int(y1),\n",
    "                #                 int(preds.shape[2] - y2)))\n",
    "                count_mat[:, :, y1:y2, x1:x2] += 1\n",
    "        assert (count_mat == 0).sum() == 0\n",
    "        preds = preds / count_mat\n",
    "        return preds\n",
    "    return crop_images, merge_fn\n",
    "\n",
    "\n",
    "def single_gpu_test(model,data_loader,out_dir=\"work_dirs/seg_diff/visualize\",opacity=0.5):\n",
    "    model.eval()\n",
    "    results = []\n",
    "    dataset = data_loader.dataset\n",
    "    prog_bar = mmcv.ProgressBar(len(dataset))\n",
    "    loader_indices = data_loader.batch_sampler\n",
    "    counter=0\n",
    "    os.makedirs(out_dir,exist_ok=True)\n",
    "    for batch_indices, data in zip(loader_indices, data_loader):\n",
    "        with torch.no_grad():\n",
    "            #print(list(data['img_metas']))\n",
    "            img_tensor = data['img'][0]\n",
    "            img_metas = data['img_metas'][0].data[0]\n",
    "            imgs = tensor2imgs(img_tensor, **img_metas[0]['img_norm_cfg'])\n",
    "            gt=dataset.get_gt_seg_map_by_idx(counter)\n",
    "            gt=torch.from_numpy(gt).unsqueeze(0).to(dtype=torch.uint8)-1\n",
    "            assert len(imgs) == len(img_metas)\n",
    "            crop_images, merge_fn = slide_inference(model, img_tensor.cuda())\n",
    "            ts=[[] for i in range(len(crop_images))]\n",
    "            zs=[[] for i in range(len(crop_images))]\n",
    "            xs=[[] for i in range(len(crop_images))]\n",
    "            outs=[]\n",
    "            temp_uc=[0]\n",
    "            for i in range(len(crop_images)):\n",
    "                def call_back(log_z,log_x_recon,t,**args):\n",
    "                    ts[i].append(t[0].item())\n",
    "                    xs[i].append(resize(input=torch.exp(log_x_recon),size=crop_images[0].shape[2:],mode='bilinear',align_corners=model.align_corners))\n",
    "                    if inference_with_uc:\n",
    "                        if ts[i][-1]==19:\n",
    "                            temp_uc_=extract_uc(xs[i][-1])\n",
    "                            temp_uc[0]=temp_uc_/temp_uc_.max()\n",
    "                        mod_log_z_by_uc(log_z,temp_uc[0],ts[i][-1])\n",
    "                    zs[i].append(resize(input=torch.exp(log_z),size=crop_images[0].shape[2:],mode='bilinear',align_corners=model.align_corners))\n",
    "                    \n",
    "                out = model.sample(crop_images[i],return_logits = True,call_back=call_back)\n",
    "                out = out['logits']\n",
    "                out = resize(input=out,size=crop_images[0].shape[2:],mode='bilinear',align_corners=model.align_corners)\n",
    "                outs.append(out)\n",
    "            out=merge_fn(outs)\n",
    "            zs=[merge_fn(i) for i in  zip(*zs)]\n",
    "            xs=[merge_fn(i) for i in  zip(*xs)]\n",
    "            ts=ts[0]\n",
    "            img=imgs[0]\n",
    "            img_meta=img_metas[0]\n",
    "            h, w, _ = img_meta['img_shape']\n",
    "            img_show = img[:h, :w, :]\n",
    "            ori_h, ori_w = img_meta['ori_shape'][:-1]\n",
    "            uc_map=[resize(extract_uc(i), (ori_h, ori_w),mode='bilinear',align_corners=model.align_corners) for i in xs]\n",
    "            img_show = mmcv.imresize(img_show, (ori_w, ori_h))\n",
    "            showed_img_out=model.show_result(img_show,torch.argmax(resize(out, (ori_h, ori_w),mode='bilinear',align_corners=model.align_corners),1).cpu(),opacity=opacity)\n",
    "            showed_gt=model.show_result(img_show,gt,opacity=opacity)\n",
    "            xs=[torch.argmax(resize(i, (ori_h, ori_w),mode='bilinear',align_corners=model.align_corners),1).cpu() for i in xs]\n",
    "            zs=[torch.argmax(resize(i, (ori_h, ori_w),mode='bilinear',align_corners=model.align_corners),1).cpu() for i in zs]\n",
    "            errs=[(i!=gt) & (gt !=255) for i in xs]\n",
    "            #print(uc_map[0])\n",
    "            uc_map=[(vis_uc(i.squeeze().cpu().numpy(),[255,255,255])).astype(\"uint8\") for i in uc_map]\n",
    "            uc_map=make_grid(uc_map)\n",
    "            cv2.imwrite(\"%s/%s_uncertainty.png\"%(out_dir,counter),uc_map)\n",
    "            err_map=[(vis_uc(i.squeeze().cpu().numpy(),[255,255,255])).astype(\"uint8\") for i in errs]\n",
    "            err_map=make_grid(err_map)\n",
    "            cv2.imwrite(\"%s/%s_err.png\"%(out_dir,counter),err_map)\n",
    "            showed_zt_out=make_grid([model.show_result(img_show,i,opacity=opacity) for i in zs])\n",
    "            showed_xt_out=make_grid([model.show_result(img_show,i,opacity=opacity) for i in xs])\n",
    "            cv2.imwrite(\"%s/%s_seg.png\"%(out_dir,counter),showed_img_out)\n",
    "            cv2.imwrite(\"%s/%s_seg_gt.png\"%(out_dir,counter),showed_gt)\n",
    "            cv2.imwrite(\"%s/%s_zt.png\"%(out_dir,counter),showed_zt_out)\n",
    "            cv2.imwrite(\"%s/%s_xt.png\"%(out_dir,counter),showed_xt_out)\n",
    "            counter+=1\n",
    "            torch.cuda.empty_cache()\n",
    "        batch_size = len(out)\n",
    "        for _ in range(batch_size):\n",
    "            prog_bar.update()\n",
    "\n",
    "\n",
    "single_gpu_test(model,data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t= 0  mask tokens:  0  mask tokens:  349696\n",
      "t= 1  mask tokens:  18426  mask tokens:  331270\n",
      "t= 2  mask tokens:  29325  mask tokens:  320371\n",
      "t= 3  mask tokens:  41055  mask tokens:  308641\n",
      "t= 4  mask tokens:  53411  mask tokens:  296285\n",
      "t= 5  mask tokens:  66723  mask tokens:  282973\n",
      "t= 6  mask tokens:  80375  mask tokens:  269321\n",
      "t= 7  mask tokens:  94900  mask tokens:  254796\n",
      "t= 8  mask tokens:  110119  mask tokens:  239577\n",
      "t= 9  mask tokens:  126167  mask tokens:  223529\n",
      "t= 10  mask tokens:  142813  mask tokens:  206883\n",
      "t= 11  mask tokens:  160051  mask tokens:  189645\n",
      "t= 12  mask tokens:  178087  mask tokens:  171609\n",
      "t= 13  mask tokens:  196827  mask tokens:  152869\n",
      "t= 14  mask tokens:  216690  mask tokens:  133006\n",
      "t= 15  mask tokens:  237119  mask tokens:  112577\n",
      "t= 16  mask tokens:  257800  mask tokens:  91896\n",
      "t= 17  mask tokens:  279769  mask tokens:  69927\n",
      "t= 18  mask tokens:  302422  mask tokens:  47274\n",
      "t= 19  mask tokens:  325770  mask tokens:  23926\n"
     ]
    }
   ],
   "source": [
    "for i,j in enumerate(zs[::-1]):\n",
    "    j=torch.argmax(j,dim=1)\n",
    "    mask=torch.sum(j==149).item()\n",
    "    unmask=torch.sum(j!=149).item()\n",
    "    print(\"t=\",i,\" mask tokens: \",mask,\" unmask tokens: \",unmask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Figure' object has no attribute 'plot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/ssd/zhaohanqing/msws/mmsegmentation/test.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcluster.weiming.win/ssd/zhaohanqing/msws/mmsegmentation/test.ipynb#ch0000002vscode-remote?line=28'>29</a>\u001b[0m \u001b[39massert\u001b[39;00m ctt[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m>\u001b[39m\u001b[39m0.9999\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcluster.weiming.win/ssd/zhaohanqing/msws/mmsegmentation/test.ipynb#ch0000002vscode-remote?line=29'>30</a>\u001b[0m fig\u001b[39m=\u001b[39mplt\u001b[39m.\u001b[39mfigure()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bcluster.weiming.win/ssd/zhaohanqing/msws/mmsegmentation/test.ipynb#ch0000002vscode-remote?line=30'>31</a>\u001b[0m fig\u001b[39m.\u001b[39;49mplot(x,at,label\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mat\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcluster.weiming.win/ssd/zhaohanqing/msws/mmsegmentation/test.ipynb#ch0000002vscode-remote?line=31'>32</a>\u001b[0m fig\u001b[39m.\u001b[39mplot(x,att,label\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39matt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcluster.weiming.win/ssd/zhaohanqing/msws/mmsegmentation/test.ipynb#ch0000002vscode-remote?line=32'>33</a>\u001b[0m fig\u001b[39m.\u001b[39mshow()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Figure' object has no attribute 'plot'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "N=20\n",
    "x=np.arange(20)\n",
    "ctt_0=0.05\n",
    "ctt_T=0.99999\n",
    "snr_0=0.9\n",
    "snr_T=0.05\n",
    "r=1\n",
    "ctt=np.linspace(ctt_0**(1/r),ctt_T**(1/r),N)**r\n",
    "snr=np.linspace(snr_0,snr_T,N)\n",
    "assert all(ctt<1)\n",
    "one_minus_ctt = 1 - ctt\n",
    "att=one_minus_ctt*snr\n",
    "assert len(ctt)==N\n",
    "assert len(att)==N\n",
    "at = att/np.concatenate([[1],att[:-1]])\n",
    "one_minus_ct = one_minus_ctt / np.concatenate([[1],one_minus_ctt[:-1]]) \n",
    "ct = 1-one_minus_ct\n",
    "bt = (1-at-ct)\n",
    "btt = (1-att-ctt)\n",
    "assert all(bt>0)\n",
    "assert all(btt>0)\n",
    "assert all(at>0)\n",
    "assert all(att>0)\n",
    "assert att[0]>=0.8\n",
    "assert ctt[0]<=0.1\n",
    "assert ctt[-1]>0.9999\n",
    "fig=plt.figure()\n",
    "ax=fig.gca()\n",
    "ax.plot(x,at,label=\"at\")\n",
    "ax.plot(x,att,label=\"att\")\n",
    "fig.show()\n",
    "fig=plt.figure()\n",
    "ax=fig.gca()\n",
    "ax.plot(x,bt,label=\"bt\")\n",
    "ax.plot(x,btt,label=\"btt\")\n",
    "fig.show()\n",
    "fig=plt.figure()\n",
    "ax=fig.gca()\n",
    "ax.plot(x,ct,label=\"ct\")\n",
    "ax.plot(x,ctt,label=\"ctt\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a3070f6bd060248ab8548100b1cd9eebfb0b202590b6b18cabf4f4d0b6666c8c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
